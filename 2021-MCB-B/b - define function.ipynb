{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'mathorcup_recom_listwise/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + 'userID2idx.pickle', 'rb') as handle:\n",
    "    userID2idx = pickle.load(handle)\n",
    "with open(data_path + 'contentTC2ID.pickle', 'rb') as handle:\n",
    "    contentTC2ID = pickle.load(handle)\n",
    "with open(data_path + 'contentID2idx.pickle', 'rb') as handle:\n",
    "    contentID2idx = pickle.load(handle)\n",
    "with open(data_path + 'idx2key.pickle', 'rb') as handle:\n",
    "    idx2key = pickle.load(handle)\n",
    "with open(data_path + 'contentID2idx_1on1.pickle', 'rb') as handle:\n",
    "    contentID2idx_1on1 = pickle.load(handle)\n",
    "with open(data_path + 'contentIdx2ID_1on1.pickle', 'rb') as handle:\n",
    "    contentIdx2ID_1on1 = pickle.load(handle)\n",
    "contentScores = torch.tensor(np.load(data_path + 'contentScores.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_distance(src, tgt, denominator=12+1e-6):\n",
    "    \"\"\"\n",
    "    :return: range in [0, 12 / denominator]\n",
    "    \"\"\"\n",
    "    a, b = (src, tgt) if src < tgt else (tgt, src)  # a < b\n",
    "    return min(b-a, a + 24 - b) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(data, default=0.1):\n",
    "    m, M = min(data), max(data)\n",
    "    if m != M:\n",
    "        return [(_ - m) / (M - m) for _ in data]\n",
    "    else:\n",
    "        return [default for _ in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do(userID):\n",
    "    idx = userID2idx[userID]\n",
    "    aaa, bb, cc = idx[0:3], idx[3:5], idx[5:7]\n",
    "    df = pd.read_csv('data_splitted_by_user_id/{}/{}/{}.csv'.format(aaa, bb, cc), dtype=str)\n",
    "\n",
    "    clickeds = np.zeros(len(contentTC2ID))\n",
    "    durations = np.zeros(len(contentTC2ID))\n",
    "    recommeds = np.zeros(len(contentTC2ID))\n",
    "    have_recommed_IDs = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        multiplier = 1 - time_distance(int(row.time), 20)\n",
    "        for icd in row.sequence.split(';'):\n",
    "            i, c, d = icd.split(':')\n",
    "            have_recommed_IDs.append(i)\n",
    "            contentIdx = contentID2idx[i]\n",
    "            if eval(c):\n",
    "                clickeds[contentIdx] += multiplier\n",
    "                durations[contentIdx] += multiplier * eval(d)\n",
    "            recommeds[contentIdx] += multiplier\n",
    "    have_recommed_IDs = set(have_recommed_IDs)\n",
    "    #print(have_recommed_IDs)\n",
    "    avg_clicked_rate = np.divide(clickeds, recommeds, out=np.zeros_like(clickeds), where=recommeds!=0)\n",
    "    avg_clicked_duration = np.divide(durations, clickeds, out=np.zeros_like(durations), where=clickeds!=0)\n",
    "    xticklabels = [idx2key[_] for _ in np.arange(len(contentTC2ID))[np.where(avg_clicked_rate != 0)]]\n",
    "    #print(avg_clicked_rate[avg_clicked_rate > 0], avg_clicked_duration[avg_clicked_duration > 0], xticklabels)\n",
    "    score1 = MinMaxScaler(avg_clicked_rate[np.where(avg_clicked_rate != 0)])\n",
    "    score2 = MinMaxScaler(avg_clicked_duration[np.where(avg_clicked_rate != 0)])\n",
    "    score = torch.tensor([x + y for x, y in zip(score1, score2)])\n",
    "    values, indices = torch.topk(score, k=min(5, len(score)))\n",
    "    \n",
    "    contentTCs = [xticklabels[_] for _ in indices]\n",
    "    counts = torch.ceil(values * 10 / torch.sum(values)).type(torch.int).tolist()\n",
    "    k = 0\n",
    "    terminal_k = 10\n",
    "    result = []\n",
    "    while True:\n",
    "        for contentTC, count in zip(contentTCs, counts):\n",
    "            # do not recommend same content\n",
    "            target_content_IDs = set(contentTC2ID[contentTC])\n",
    "            #print(contentTC, 'target counts:', len(target_content_IDs), 'â†’ ', end='')\n",
    "            target_content_IDs = target_content_IDs - have_recommed_IDs\n",
    "            #print(len(target_content_IDs))\n",
    "\n",
    "            # map to index (range in 2510703)\n",
    "            target_content_Idxes = [contentID2idx_1on1[_] for _ in target_content_IDs]\n",
    "\n",
    "            # scores\n",
    "            target_scores = contentScores[target_content_Idxes]\n",
    "            top_values, top_indices = torch.topk(target_scores, min(count, len(target_scores)))\n",
    "            for i, value in enumerate(top_values):\n",
    "                indice = top_indices[i]\n",
    "                target_ID = contentIdx2ID_1on1[target_content_Idxes[indice]]\n",
    "                result.append(target_ID)\n",
    "                have_recommed_IDs.add(target_ID)\n",
    "                k += 1\n",
    "                if k == terminal_k:\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recomm_result_df = pd.read_csv(data_path + 'recomm_result.csv', dtype=str, header=None, names=['userID', 'contentID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2263674210\n",
       "1       2407104270\n",
       "2       1850876254\n",
       "3       2208092618\n",
       "4       1642551254\n",
       "           ...    \n",
       "4995    1167815814\n",
       "4996    2452835534\n",
       "4997    1517277558\n",
       "4998    2223184164\n",
       "4999    1423562960\n",
       "Name: userID, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateIDs = recomm_result_df['userID']\n",
    "candidateIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0699427'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userID2idx['1424832354']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1424832354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'133685078880;133675383025;133678877302;133677361798;133670767481;133672860139;133682790306;133672736156;133645134415;133463032961'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(candidateIDs[2922])\n",
    "sequence = do(candidateIDs[2922])\n",
    "';'.join(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['506452865;507146538;507040429;506448411;507802432;505966037;509131249;507457950;506466776;507667879', '133675654658;133657843524;133682981897;133682817032;133677387027;133684483942;133674211918;133673025741;133671667695;133682133146', '133675493354;133682019937;133684077954;507760297;508112085;509016369;507245921;506841346;506585559;507903233', '133673251676;133666957709;133678083250;133668617622;133678922321;133675348328;509152890;506929325;133682016014;133684645963', '133686242032;133663752853;133663752851;133680924496;133682743655;133684776889;133677424853;133677424856;133672814290;133665825681', '133671447633;133682877386;133682743655;133664200927;133679383008;133679017560;133667961560;133655999000;133666860087;508363359']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i, id in tqdm(enumerate(candidateIDs)):\n",
    "    result.append(';'.join(do(id)))\n",
    "    if i == 5:\n",
    "        break\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-1982069bc6f7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m result_df = pd.DataFrame(\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[1;33m{\u001B[0m\u001B[1;34m'candidateIDs'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mcandidateIDs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'sequence'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m )\n\u001B[0;32m      4\u001B[0m \u001B[0mresult_df\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(\n",
    "    {'candidateIDs': candidateIDs, 'sequence': result}\n",
    ")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(data_path + 'recomm_result_df' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}