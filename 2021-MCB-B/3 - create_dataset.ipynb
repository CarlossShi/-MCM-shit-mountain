{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Slice of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x241efba91d0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'mathorcup_recom_listwise/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pandas.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requestID</th>\n",
       "      <th>userID</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>719708291_1635480753679_2960</td>\n",
       "      <td>1439416582</td>\n",
       "      <td>20211029</td>\n",
       "      <td>12</td>\n",
       "      <td>509057416;133681226775;509178914;509178914;508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>679978594_1635491281923_1780</td>\n",
       "      <td>1359957188</td>\n",
       "      <td>20211029</td>\n",
       "      <td>15</td>\n",
       "      <td>508829941;133686019323;508830405;133677444707;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      requestID      userID      date time  \\\n",
       "0  719708291_1635480753679_2960  1439416582  20211029   12   \n",
       "1  679978594_1635491281923_1780  1359957188  20211029   15   \n",
       "\n",
       "                                            sequence  \n",
       "0  509057416;133681226775;509178914;509178914;508...  \n",
       "1  508829941;133686019323;508830405;133677444707;...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(data_path + 'test_data.csv', dtype=str, nrows=2)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>requestID</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000014754</td>\n",
       "      <td>500007377_1635422685108_3822</td>\n",
       "      <td>20211028</td>\n",
       "      <td>20</td>\n",
       "      <td>133669542676:1:148;133658378700:1:16;133650937...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000019906</td>\n",
       "      <td>500009953_1635375063077_3893</td>\n",
       "      <td>20211028</td>\n",
       "      <td>06</td>\n",
       "      <td>133679233276:0:0;133658338671:0:0;133677846615...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID                     requestID      date time  \\\n",
       "0  1000014754  500007377_1635422685108_3822  20211028   20   \n",
       "1  1000019906  500009953_1635375063077_3893  20211028   06   \n",
       "\n",
       "                                            sequence  \n",
       "0  133669542676:1:148;133658378700:1:16;133650937...  \n",
       "1  133679233276:0:0;133658338671:0:0;133677846615...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(data_path + 'train_data.csv', dtype=str, nrows=2)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WORD EMBEDDINGS: ENCODING LEXICAL SEMANTICS](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)\n",
    "\n",
    "``` python\n",
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)\n",
    "```\n",
    "\n",
    "Out:\n",
    "```\n",
    "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519]],\n",
    "       grad_fn=<EmbeddingBackward0>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UserID Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1000014754', '1000019906'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_userID = set(train_df['userID'])\n",
    "train_userID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1000014754': 0, '1000019906': 1}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userID2idx = {_:i for i, _ in enumerate(train_userID)}\n",
    "userID2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(2, 4)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userID_embeds = nn.Embedding(len(userID2idx), 4)\n",
    "userID_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item ID Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icd2i(icd):\n",
    "    i, c, d = icd.split(':')\n",
    "    return i\n",
    "\n",
    "\n",
    "def seq2itemID(sequence):\n",
    "    \"\"\"\n",
    "    :param sequence: {str}, e.g. '133679233276:0:0;133658338671:0:0;133677846615:0:0'\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {icd2i(icd) for icd in sequence.split(';')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How can I find the union on a list of sets in Python? [duplicate]](https://stackoverflow.com/a/31253153/12224183)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'133650937891',\n",
       " '133658338671',\n",
       " '133658378700',\n",
       " '133658512070',\n",
       " '133660220952',\n",
       " '133660292493',\n",
       " '133663959878',\n",
       " '133665337307',\n",
       " '133669542676',\n",
       " '133673154438',\n",
       " '133677667554',\n",
       " '133677842247',\n",
       " '133677846615',\n",
       " '133678000841',\n",
       " '133679233276',\n",
       " '506770575',\n",
       " '506898339',\n",
       " '507531461',\n",
       " '507570279',\n",
       " '507605194'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_itemID = set.union(*[seq2itemID(seq) for seq in train_df['sequence']])\n",
    "train_itemID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'133658512070': 0,\n",
       " '506898339': 1,\n",
       " '133669542676': 2,\n",
       " '507570279': 3,\n",
       " '133660220952': 4,\n",
       " '133658378700': 5,\n",
       " '133665337307': 6,\n",
       " '133650937891': 7,\n",
       " '507531461': 8,\n",
       " '133677842247': 9,\n",
       " '133663959878': 10,\n",
       " '133677846615': 11,\n",
       " '133677667554': 12,\n",
       " '133678000841': 13,\n",
       " '506770575': 14,\n",
       " '133673154438': 15,\n",
       " '507605194': 16,\n",
       " '133660292493': 17,\n",
       " '133679233276': 18,\n",
       " '133658338671': 19}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemID2idx = {_:i for i, _ in enumerate(train_itemID)}\n",
    "itemID2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(20, 4)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemID_embeds = nn.Embedding(len(itemID2idx), 4)\n",
    "itemID_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "[torch.utils.data.Dataset(*args, **kwds)](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icd2dict(icd):\n",
    "    i, c, d = icd.split(':')\n",
    "    return {'itemID': i, 'clicked': bool(eval(c)), 'duration': eval(d)}\n",
    "\n",
    "\n",
    "class Sequence:\n",
    "    def __init__(self, sequence):\n",
    "        \"\"\"\n",
    "        :param sequence: {str}, e.g. '133679233276:0:0;133658338671:0:0;133677846615:0:0'\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.sequence = [icd2dict(icd) for icd in sequence.split(';')]\n",
    "        self.length = len(self.sequence)\n",
    "        self.avg_clicked = np.mean([_['clicked'] for _ in self.sequence])\n",
    "        self.sum_duration = np.sum([_['duration'] for _ in self.sequence])\n",
    "        self.avg_duration = self.sum_duration / self.length\n",
    "    def seq_print(self):\n",
    "        pprint.pprint(self.sequence)\n",
    "        print('length of sequence:', self.len_sequence)\n",
    "        print('average clicked:', self.avg_clicked)\n",
    "        print('average duration:', self.avg_duration)\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, userID2idx, itemID2idx):\n",
    "        self.length = len(df)\n",
    "        \n",
    "        self.userID2idx = userID2idx\n",
    "        self.itemID2idx = itemID2idx\n",
    "    \n",
    "        self.userLen = len(userID2idx)\n",
    "        self.itemLen = len(itemID2idx)\n",
    "        \n",
    "        self.userID, self.requestID = df['userID'], df['requestID']  # string\n",
    "        self.userIdx = torch.tensor([userID2idx[_] for _ in self.userID], dtype=torch.int32)  # {Tensor: (len(df),)}\n",
    "        \n",
    "        # self.date = torch.tensor(df.astype({'date': 'int32'})['date'])  # e.g. 20220106\n",
    "        # self.time = torch.tensor(df.astype({'time': 'int8'})['time'])  # range in [00, 23]\n",
    "        \n",
    "        self.date = torch.zeros([len(df), 6], dtype=torch.int16)\n",
    "        for _ in range(len(df)):\n",
    "            self.date[_, 0] = int(df.loc[_, 'time'])  # hour\n",
    "            date = df.loc[_, 'date']\n",
    "            self.date[_, 3] = int(date[:4])  # year\n",
    "            self.date[_, 4] = int(date[4:6])  # month\n",
    "            self.date[_, 5] = int(date[6:8])  # day\n",
    "            \n",
    "        self.sequence = [Sequence(_) for _ in df['sequence']]\n",
    "        self.max_sum_duration = max([_.sum_duration for _ in self.sequence])\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def __getitem__(self, idx):\n",
    "        # udt = torch.tensor([self.userIdx[idx], self.date[idx], self.time[idx]], dtype=torch.int32)\n",
    "        userIdx = self.userIdx[idx]\n",
    "        date = self.date[idx]\n",
    "        sequence = self.sequence[idx]\n",
    "        itemID = torch.tensor([self.itemID2idx[_['itemID']] for _ in self.sequence[idx].sequence], dtype=torch.int32)\n",
    "        duration = torch.tensor([_['duration'] for _ in self.sequence[idx].sequence], dtype=torch.int32)\n",
    "        return userIdx, date, itemID, duration, torch.tensor(len(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>requestID</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000014754</td>\n",
       "      <td>500007377_1635422685108_3822</td>\n",
       "      <td>20211028</td>\n",
       "      <td>20</td>\n",
       "      <td>133669542676:1:148;133658378700:1:16;133650937...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000019906</td>\n",
       "      <td>500009953_1635375063077_3893</td>\n",
       "      <td>20211028</td>\n",
       "      <td>06</td>\n",
       "      <td>133679233276:0:0;133658338671:0:0;133677846615...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID                     requestID      date time  \\\n",
       "0  1000014754  500007377_1635422685108_3822  20211028   20   \n",
       "1  1000019906  500009953_1635375063077_3893  20211028   06   \n",
       "\n",
       "                                            sequence  \n",
       "0  133669542676:1:148;133658378700:1:16;133650937...  \n",
       "1  133679233276:0:0;133658338671:0:0;133677846615...  "
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(train_df, userID2idx, itemID2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "853"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.max_sum_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, dtype=torch.int32),\n",
       " tensor([  20,    0,    0, 2021,   10,   28], dtype=torch.int16),\n",
       " tensor([ 2,  5,  7, 10,  1,  0,  4, 14, 15, 17, 17], dtype=torch.int32),\n",
       " tensor([148,  16,  85, 221,   0, 101,  60,   0, 102,   0, 120],\n",
       "        dtype=torch.int32),\n",
       " tensor(11))"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1, dtype=torch.int32),\n",
       " tensor([   6,    0,    0, 2021,   10,   28], dtype=torch.int16),\n",
       " tensor([18, 19, 11, 12, 16,  6,  9,  8,  3, 13], dtype=torch.int32),\n",
       " tensor([  0,   0,   0,   0, 113,   0, 251,   0,   0,   0], dtype=torch.int32),\n",
       " tensor(10))"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'length': 2,\n",
       " 'userID2idx': {'1000014754': 0, '1000019906': 1},\n",
       " 'itemID2idx': {'133658512070': 0,\n",
       "  '506898339': 1,\n",
       "  '133669542676': 2,\n",
       "  '507570279': 3,\n",
       "  '133660220952': 4,\n",
       "  '133658378700': 5,\n",
       "  '133665337307': 6,\n",
       "  '133650937891': 7,\n",
       "  '507531461': 8,\n",
       "  '133677842247': 9,\n",
       "  '133663959878': 10,\n",
       "  '133677846615': 11,\n",
       "  '133677667554': 12,\n",
       "  '133678000841': 13,\n",
       "  '506770575': 14,\n",
       "  '133673154438': 15,\n",
       "  '507605194': 16,\n",
       "  '133660292493': 17,\n",
       "  '133679233276': 18,\n",
       "  '133658338671': 19},\n",
       " 'userLen': 2,\n",
       " 'itemLen': 20,\n",
       " 'userID': 0    1000014754\n",
       " 1    1000019906\n",
       " Name: userID, dtype: object,\n",
       " 'requestID': 0    500007377_1635422685108_3822\n",
       " 1    500009953_1635375063077_3893\n",
       " Name: requestID, dtype: object,\n",
       " 'userIdx': tensor([0, 1], dtype=torch.int32),\n",
       " 'date': tensor([[  20,    0,    0, 2021,   10,   28],\n",
       "         [   6,    0,    0, 2021,   10,   28]], dtype=torch.int16),\n",
       " 'sequence': [<__main__.Sequence at 0x24181a4af70>,\n",
       "  <__main__.Sequence at 0x24181a2a130>]}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "\n",
    "[torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None, generator=None, *, prefetch_factor=2, persistent_workers=False)](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.DataLoader)\n",
    "\n",
    "[Guidelines for assigning num_workers to DataLoader](https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813)\n",
    "\n",
    "[How to use 'collate_fn' with dataloaders?](https://stackoverflow.com/a/65875359/12224183)\n",
    "collate\n",
    "英 [kəˈleɪt]  美 [kəˈleɪt] \n",
    "vt. 核对，校对；校勘\n",
    "\n",
    "[reshaping a tensor with padding in pytorch](https://stackoverflow.com/a/53126241/12224183)\n",
    "\n",
    "Examples:\n",
    "1. [Custom datasets in Pytorch — Part 2. Text (Machine Translation)\n",
    "](https://towardsdatascience.com/custom-datasets-in-pytorch-part-2-text-machine-translation-71c41a3e994e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2780, 0.8161, 0.5097, 0.2991, 0.7889])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = torch.rand((5))\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2780, 0.8161, 0.5097, 0.2991, 0.7889, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = F.pad(input=source, pad=(0, 2), mode='constant', value=0)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemLen = train_dataset.itemLen\n",
    "itemLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [How to use 'collate_fn' with dataloaders?]\n",
    "# (https://stackoverflow.com/a/65875359/12224183)\n",
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    :param data: list of tuples with (utd, sequence idx, labels, len(labels))\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    userIdxes, dates, itemIdxes, durations, lengths = list(zip(*data))\n",
    "    return (\n",
    "        torch.stack(userIdxes),\n",
    "        torch.stack(dates),\n",
    "        pad_sequence(itemIdxes, batch_first=True, padding_value=itemLen),  # if -1, index out of range in Embedding()!!  \n",
    "        pad_sequence(durations, batch_first=True, padding_value=-1), \n",
    "        torch.stack(lengths)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0]  # user index with shape: torch.Size([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   6,    0,    0, 2021,   10,   28],\n",
       "        [  20,    0,    0, 2021,   10,   28]], dtype=torch.int16)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[1]  # date with shape: torch.Size([2, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  5,  7, 10,  1,  0,  4, 14, 15, 17, 17],\n",
       "        [18, 19, 11, 12, 16,  6,  9,  8,  3, 13, 20]], dtype=torch.int32)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[2]  # item index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0, 113,   0, 251,   0,   0,   0,  -1],\n",
       "        [148,  16,  85, 221,   0, 101,  60,   0, 102,   0, 120]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[3]  # duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 11])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[4]  # length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "    print(i, batch[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Examples: \n",
    "1. [TRAINING WITH PYTORCH](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html#training-with-pytorch)\n",
    "2. [LANGUAGE MODELING WITH NN.TRANSFORMER AND TORCHTEXT](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)\n",
    "3. [SEQUENCE MODELS AND LONG SHORT-TERM MEMORY NETWORKS](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#sphx-glr-beginner-nlp-sequence-models-tutorial-py)\n",
    "4. [WORD EMBEDDINGS: ENCODING LEXICAL SEMANTICS](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#word-embeddings-encoding-lexical-semantics)\n",
    "5. [A detailed guide to PyTorch’s nn.Transformer() module.](https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer to deal with sequences of inconsistent length?**\n",
    "\n",
    "[Issues using pack_padded_sequence #1522](https://github.com/pytorch/xla/issues/1522#issuecomment-606300555)\n",
    "> For transformer based models, we don't do packing (doesn't make sense for attention). AFAIU pad/pack produces a different shape tensor every time, one dimension of the tensor is number of non-pad tokens in the batch, which is likely highly variable from batch to batch. The reasoning behind it is, it saves flops that way. However, this must be causing a ton of compiles on TPUs due to shapes varying all over the place.\n",
    "\n",
    "[How to create batches of a list of varying dimension tensors?](https://discuss.pytorch.org/t/how-to-create-batches-of-a-list-of-varying-dimension-tensors/50773)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Meaning of Transformer parameters?**\n",
    "\n",
    "[TRANSFORMER](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#transformer)\n",
    "\n",
    "[Difference between src_mask and src_key_padding_mask](https://stackoverflow.com/questions/62170439/difference-between-src-mask-and-src-key-padding-mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nn.transformer with embedding example**\n",
    "\n",
    "[nn.Transformer explaination](https://discuss.pytorch.org/t/nn-transformer-explaination/53175/3)\n",
    "> I’m having the same problem, but for the example part i guess it is a mistake from their side\n",
    "nn.transformer doesn’t take source and target vocab size as it is only implementing the transformer part without the embeddings layer on the input data and without the linear layer on the output of the decoder,\n",
    "in order to make it work d_model will be your embedding size and call an embedding layer on the source and on the target and the output of the transformer should pass through a linear that gets you the target vocab size\n",
    "> ```python\n",
    "self.embed_src = nn.Embedding(src_vocab, emb_dim)\n",
    "self.embed_trg = nn.Embedding(trg_vocab, emb_dim)\n",
    "self.model = nn.Transformer( d_model = emb_dim,nhead=heads, self.num_encoder_layers=N, num_decoder_layers=N)\n",
    "self.out_linear = nn.Linear(emb_dim, trg_vocab)\n",
    "> ```\n",
    "> for the forward function it should be\n",
    "> ```python\n",
    "src = self.embed_src(src) \n",
    "trg = self.embed_trg(trg)\n",
    "output = self.model(src, trg)\n",
    "output = self.out(output)\n",
    "> ```\n",
    "\n",
    "[ojus1/Date2Vec - GitHub](https://github.com/ojus1/Date2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.date2vec import Date2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1000014754': 0, '1000019906': 1}"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userID2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'133658512070': 0,\n",
       " '506898339': 1,\n",
       " '133669542676': 2,\n",
       " '507570279': 3,\n",
       " '133660220952': 4,\n",
       " '133658378700': 5,\n",
       " '133665337307': 6,\n",
       " '133650937891': 7,\n",
       " '507531461': 8,\n",
       " '133677842247': 9,\n",
       " '133663959878': 10,\n",
       " '133677846615': 11,\n",
       " '133677667554': 12,\n",
       " '133678000841': 13,\n",
       " '506770575': 14,\n",
       " '133673154438': 15,\n",
       " '507605194': 16,\n",
       " '133660292493': 17,\n",
       " '133679233276': 18,\n",
       " '133658338671': 19}"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemID2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(20, 4)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemID_embeds = nn.Embedding(len(itemID2idx), 4)\n",
    "itemID_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemID_embeds(torch.zeros([2,3], dtype=torch.int)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Src Dim Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 16])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N , dim_user, dim_date = 4, 16, 16\n",
    "u = torch.zeros([N, dim_user])  # (N, dim_user)\n",
    "d = torch.zeros([N, dim_date])  # (N, dim_date)\n",
    "torch.transpose(torch.stack([u,d]), 1, 0).shape  # (N, S, E`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformer Output Dim Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 512])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    "src = torch.rand((10, 32, 512))  # (S, N, E)\n",
    "tgt = torch.rand((20, 32, 512))  # (S, N, E)\n",
    "out = transformer_model(src, tgt)\n",
    "out.shape\n",
    "# RuntimeError: the feature number of src and tgt must be equal to d_model\n",
    "# RuntimeError: the batch number of src and tgt must be equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Output Dim Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 1])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, T, d_model = 4, 16, 512\n",
    "linear = nn.Linear(d_model, 1)\n",
    "out = torch.rand([N, T, d_model])\n",
    "out = linear(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, user_len, item_len, d_model=6):\n",
    "        super(Model, self).__init__()\n",
    "        self.userID_embeddings = nn.Embedding(user_len, d_model)\n",
    "        self.itemID_embeddings = nn.Embedding(item_len + 1, d_model)  # if not +1, index out of range in Embedding()!!\n",
    "        self.date2vec = Date2Vec(k=32, act='sin')  # (N, 6) -> (N, dim_date)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,  # default is 512\n",
    "            nhead=3,  # default is 4\n",
    "            num_encoder_layers=6, \n",
    "            num_decoder_layers=6, \n",
    "            dim_feedforward=2048, \n",
    "            dropout=0.1, \n",
    "            activation='relu', \n",
    "            custom_encoder=None, \n",
    "            custom_decoder=None, \n",
    "            layer_norm_eps=1e-05, \n",
    "            batch_first=True, \n",
    "            device=None, \n",
    "            dtype=None\n",
    "        )  # (N, T, E) -> (N, T, E)\n",
    "        self.linear = nn.Linear(d_model, 1)  # (N, T, E) -> (N, T, 1)\n",
    "        \n",
    "    def forward(self, u, d, i, tgt_mask, tgt_key_padding_mask):\n",
    "        \"\"\"\n",
    "        :param u: {Tensor: (N,)}, user indexes\n",
    "        :param d: {Tensor: (N, 6)}, date\n",
    "        :param i: {Tensor: (N, T)}, item indexes (target sentence)\n",
    "        \"\"\"\n",
    "        # prepare src\n",
    "        u = self.userID_embeddings(u)  # (N, dim_user)\n",
    "        d = self.date2vec(d.float())  # (N, dim_date)\n",
    "        ud = torch.transpose(torch.stack([u,d]), 1, 0)  # (N, S, E)\n",
    "        # prepare tgt\n",
    "        i = self.itemID_embeddings(i)  # (N, T, E)\n",
    "        # calculate out\n",
    "        out = self.transformer(src=ud, tgt=i, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask)  # (N, T, E)\n",
    "        out = self.linear(out)  # (N, T, 1)\n",
    "        return out\n",
    "    \n",
    "    def get_tgt_mask(self, size) -> torch.tensor:\n",
    "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        mask = torch.tril(torch.ones(size, size) == 1)  # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf'))  # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0))  # Convert ones to 0\n",
    "\n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        return (matrix == pad_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1000014754', '1000019906'}"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_userID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (userID_embeddings): Embedding(2, 6)\n",
       "  (itemID_embeddings): Embedding(21, 6)\n",
       "  (date2vec): Date2Vec(\n",
       "    (fc1): Linear(in_features=6, out_features=16, bias=True)\n",
       "    (fc2): Linear(in_features=6, out_features=16, bias=True)\n",
       "    (d2): Dropout(p=0.3, inplace=False)\n",
       "    (fc3): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (d3): Dropout(p=0.3, inplace=False)\n",
       "    (fc4): Linear(in_features=16, out_features=6, bias=True)\n",
       "    (fc5): Linear(in_features=6, out_features=6, bias=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "          (norm1): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=6, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(user_len=len(train_userID), item_len=len(train_itemID))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th batch\n",
      "userIdxes: tensor([0, 1], dtype=torch.int32)\n",
      "dates: tensor([[  20,    0,    0, 2021,   10,   28],\n",
      "        [   6,    0,    0, 2021,   10,   28]], dtype=torch.int16)\n",
      "itemIdxes: tensor([[ 2,  5,  7, 10,  1,  0,  4, 14, 15, 17, 17],\n",
      "        [18, 19, 11, 12, 16,  6,  9,  8,  3, 13, 20]], dtype=torch.int32)\n",
      "durations: tensor([[148,  16,  85, 221,   0, 101,  60,   0, 102,   0, 120],\n",
      "        [  0,   0,   0,   0, 113,   0, 251,   0,   0,   0,  -1]],\n",
      "       dtype=torch.int32) torch.Size([2, 11])\n",
      "lengths: tensor([11, 10]) torch.Size([2])\n",
      "preds: tensor([[1.1449, 0.1882, 0.4989, 1.0057, 0.9262, 0.6131, 0.1845, 0.5120, 1.1680,\n",
      "         1.1465, 0.5812],\n",
      "        [0.9523, 0.8888, 0.8726, 1.0284, 0.6494, 0.8173, 0.6586, 0.8271, 0.5834,\n",
      "         0.8427, 0.5406]], grad_fn=<SqueezeBackward0>)\n",
      "preds.shape: torch.Size([2, 11])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "    userIdxes, dates, itemIdxes, durations, lengths = batch\n",
    "    print(i, 'th batch')\n",
    "    print('userIdxes:', userIdxes)\n",
    "    print('dates:', dates)\n",
    "    print('itemIdxes:', itemIdxes)\n",
    "    print('durations:', durations, durations.shape)\n",
    "    print('lengths:', lengths, lengths.shape)\n",
    "    \n",
    "    tgt_mask = model.get_tgt_mask(size=itemIdxes.size(1))\n",
    "    tgt_key_padding_mask = model.create_pad_mask(matrix=itemIdxes, pad_token=itemLen)\n",
    "    \n",
    "    preds = model(\n",
    "        userIdxes, \n",
    "        dates, \n",
    "        itemIdxes, \n",
    "        tgt_mask=tgt_mask, \n",
    "        tgt_key_padding_mask=tgt_key_padding_mask\n",
    "    ).squeeze()\n",
    "    print('preds:', preds)\n",
    "    print('preds.shape:', preds.shape)  # (N, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "          True]])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_key_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1449, 0.1882, 0.4989, 1.0057, 0.9262, 0.6131, 0.1845, 0.5120, 1.1680,\n",
       "         1.1465, 0.5812],\n",
       "        [0.9523, 0.8888, 0.8726, 1.0284, 0.6494, 0.8173, 0.6586, 0.8271, 0.5834,\n",
       "         0.8427, 0.5406]], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "[Custom loss functions](https://discuss.pytorch.org/t/custom-loss-functions/29387/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  4,  0, -1],\n",
       "        [ 0,  4,  0,  4,  0]])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations = torch.tensor([[4, 0, 4, 0, -1],[0, 4, 0, 4, 0]])\n",
    "durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, -1,  1, -1,  1],\n",
       "        [-1,  1, -1,  1, -1]])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.tensor([[1, -1, 1, -1, 1], [-1, 1, -1, 1, -1]])\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for Element  > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 0, 9, 0, 0],\n",
       "        [0, 9, 0, 9, 0]])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.gt(0) * (durations - preds) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(durations.gt(0) * (durations - preds) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for Element == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations.eq(0) * (torch.sign(preds) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2384, 0.0000, 0.2384, 0.0000],\n",
       "        [0.2384, 0.0000, 0.2384, 0.0000, 0.2384]])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations.eq(0) * (torch.tanh(preds) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1920)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(durations.eq(0) * (torch.tanh(preds) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for Terminal Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(durations.gt(-1) * preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(preds, durations, total_energy):\n",
    "    \"\"\"\n",
    "    :param output: (N, T)\n",
    "    :param target: (N, T)\n",
    "    :param target: (N)\n",
    "    \"\"\"\n",
    "    ge0_loss = torch.sum(durations.gt(0) * (durations - preds * total_energy) ** 2)  # [0, 4*te^2)\n",
    "    eq0_loss = torch.sum(durations.eq(0) * (torch.tanh(preds) + 1))  # range in [0, 2)\n",
    "    term_loss = (1 - torch.sum(torch.abs(durations.gt(-1) * preds))) ** 2  # range in [0, (T-1)^2)\n",
    "    print('ge0_loss, eq0_loss, term_loss:', ge0_loss, eq0_loss, term_loss)\n",
    "    return ge0_loss / total_energy + 100 * eq0_loss + term_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, -1,  1, -1,  1],\n",
       "        [-1,  1, -1,  1, -1]])"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  4,  0, -1],\n",
       "        [ 0,  4,  0,  4,  0]])"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ge0_loss, eq0_loss, term_loss: tensor(1024) tensor(1.1920) tensor(64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1307.2291)"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_loss(preds, durations, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ge0_loss, eq0_loss, term_loss: tensor(0.) tensor(5.) tensor(0.0400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5000.0400)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_loss(durations/20, durations, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 1., 0.],\n",
       "        [1., 0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations.eq(0) * (torch.sign(durations/20) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = 'cpu'\n",
    "model = Model(user_len=len(train_userID), item_len=len(train_itemID))\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_fn = my_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, opt, loss_fn, dataloader, total_energy):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        userIdxes, dates, itemIdxes, durations, lengths = batch\n",
    "\n",
    "        tgt_mask = model.get_tgt_mask(size=itemIdxes.size(1))\n",
    "        tgt_key_padding_mask = model.create_pad_mask(matrix=itemIdxes, pad_token=itemLen)\n",
    "\n",
    "        preds = model(\n",
    "            userIdxes, \n",
    "            dates, \n",
    "            itemIdxes, \n",
    "            tgt_mask=tgt_mask, \n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        ).squeeze()  # (N, T)\n",
    "        \n",
    "        loss = loss_fn(preds, durations, total_energy)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.detach().item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "853"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.max_sum_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Epoch 1 -------------------------\n",
      "ge0_loss, eq0_loss, term_loss: tensor(350897.1875, grad_fn=<SumBackward0>) tensor(3.1237, grad_fn=<SumBackward0>) tensor(234.1014, grad_fn=<PowBackward0>)\n",
      "Training loss: 3769.1638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "train_loss_list, validation_loss_list = [], []\n",
    "\n",
    "for epoch in range(1):\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
    "\n",
    "    train_loss = train_loop(\n",
    "        model=model, \n",
    "        opt=opt, \n",
    "        loss_fn=loss_fn, \n",
    "        dataloader=train_dataloader,\n",
    "        total_energy=train_dataset.max_sum_duration\n",
    "    )\n",
    "    train_loss_list += [train_loss]\n",
    "\n",
    "    print(f\"Training loss: {train_loss:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ge0_loss, eq0_loss, term_loss: tensor(212472.1250, grad_fn=<SumBackward0>) tensor(3.2651, grad_fn=<SumBackward0>) tensor(221.0641, grad_fn=<PowBackward0>)\n",
      "ge0_loss, eq0_loss, term_loss: tensor(140877.7656, grad_fn=<SumBackward0>) tensor(6.4822, grad_fn=<SumBackward0>) tensor(92.5187, grad_fn=<PowBackward0>)\n",
      "ge0_loss, eq0_loss, term_loss: tensor(218546.6406, grad_fn=<SumBackward0>) tensor(6.1948, grad_fn=<SumBackward0>) tensor(95.0685, grad_fn=<PowBackward0>)\n",
      "ge0_loss, eq0_loss, term_loss: tensor(493922.3125, grad_fn=<SumBackward0>) tensor(3.0103, grad_fn=<SumBackward0>) tensor(240.8879, grad_fn=<PowBackward0>)\n",
      "ge0_loss, eq0_loss, term_loss: tensor(765295.1875, grad_fn=<SumBackward0>) tensor(2.1402, grad_fn=<SumBackward0>) tensor(321.0149, grad_fn=<PowBackward0>)\n",
      "ge0_loss, eq0_loss, term_loss: tensor(744933.3750, grad_fn=<SumBackward0>) tensor(1.8623, grad_fn=<SumBackward0>) tensor(325.3593, grad_fn=<PowBackward0>)\n",
      "ge0_loss, eq0_loss, term_loss: tensor(665069.3125, grad_fn=<SumBackward0>) tensor(2.7540, grad_fn=<SumBackward0>) tensor(256.4470, grad_fn=<PowBackward0>)\n",
      "ge0_loss, eq0_loss, term_loss: tensor(620342.2500, grad_fn=<SumBackward0>) tensor(2.6643, grad_fn=<SumBackward0>) tensor(258.4426, grad_fn=<PowBackward0>)\n",
      "ge0_loss, eq0_loss, term_loss: tensor(509180.7188, grad_fn=<SumBackward0>) tensor(2.9381, grad_fn=<SumBackward0>) tensor(238.6998, grad_fn=<PowBackward0>)\n",
      "ge0_loss, eq0_loss, term_loss: tensor(333718.6875, grad_fn=<SumBackward0>) tensor(4.8099, grad_fn=<SumBackward0>) tensor(140.5435, grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/test')\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train_loop(\n",
    "        model=model, \n",
    "        opt=opt, \n",
    "        loss_fn=loss_fn, \n",
    "        dataloader=train_dataloader,\n",
    "        total_energy=train_dataset.max_sum_duration\n",
    "    )\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-475f16fb44b68f32\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-475f16fb44b68f32\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}